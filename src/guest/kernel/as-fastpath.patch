diff -Naur wo_vivid/.config c_vivid/.config
--- wo_vivid/.config	2016-02-10 11:50:05.020000000 +0530
+++ c_vivid/.config	2016-02-10 11:11:10.148000000 +0530
@@ -1,6 +1,6 @@
 #
 # Automatically generated file; DO NOT EDIT.
-# Linux/x86_64 3.19.0-37-generic Kernel Configuration
+# Linux/x86 3.19.8-ckt9 Kernel Configuration
 #
 CONFIG_64BIT=y
 CONFIG_X86_64=y
@@ -2320,6 +2320,7 @@
 CONFIG_MACINTOSH_DRIVERS=y
 CONFIG_MAC_EMUMOUSEBTN=m
 CONFIG_NETDEVICES=y
+CONFIG_AS_FASTPATH=y
 CONFIG_MII=m
 CONFIG_NET_CORE=y
 CONFIG_BONDING=m
diff -Naur wo_vivid/drivers/net/Kconfig c_vivid/drivers/net/Kconfig
--- wo_vivid/drivers/net/Kconfig	2016-02-10 11:51:22.420000000 +0530
+++ c_vivid/drivers/net/Kconfig	2016-02-10 11:12:14.756000000 +0530
@@ -24,7 +24,39 @@
 # All the following symbols are dependent on NETDEVICES - do not repeat
 # that for each of the symbols.
 if NETDEVICES
-
+config AS_FASTPATH
+	default n
+	bool "Application Specific FastPath"
+#	select NAMESPACES
+#	select NET_NS
+#	select NETFILTER
+#	select NETFILTER_ADVANCED
+#	select NF_CONNTRACK
+#	select NF_CONNTRACK_EVENTS
+#	select NF_CONNTRACK_FTP
+#	select NF_CONNTRACK_TFTP
+#	select NETFILTER_XTABLES
+#	select NF_CONNTRACK_IPV4
+#	select NF_CONNTRACK_PROC_COMPAT
+#	select IP_NF_IPTABLES
+#	select IP_NF_MATCH_ADDRTYPE
+#	select IP_NF_FILTER
+#	select NF_NAT_IPV4
+#	select IP_NF_TARGET_REJECT
+#	select NF_NAT_NEEDED
+#	select IP_NF_TARGET_MASQUERADE
+#	select IP_NF_TARGET_REDIRECT
+#	select NF_NAT_FTP
+#	select NF_NAT_TFTP
+#	select IP_NF_MANGLE
+#	select VLAN_8021Q
+#	select INET_AH
+#	select PPP
+#	select PPPOE
+	---help---
+	  Enables application specific fastpath n/w stack that
+	  accelerates the throughput for forwarding, firewall, NAT and IPsec
+	  over native Linux stack.
 config MII
 	tristate
 
diff -Naur wo_vivid/drivers/net/virtio_net.c c_vivid/drivers/net/virtio_net.c
--- wo_vivid/drivers/net/virtio_net.c	2016-02-10 11:52:26.944000000 +0530
+++ c_vivid/drivers/net/virtio_net.c	2016-02-10 11:12:57.264000000 +0530
@@ -36,6 +36,14 @@
 module_param(csum, bool, 0444);
 module_param(gso, bool, 0444);
 
+#ifdef CONFIG_AS_FASTPATH
+#define AS_FP_PROCEED   1
+#define AS_FP_STOLEN    2
+typedef int (*devfp_hook_t)(struct sk_buff *skb, struct net_device *dev);
+/* Headroom required for IPSec processing in ASF */
+#define EXTRA_HEADROOM 128
+#endif
+
 /* FIXME: MTU in config. */
 #define GOOD_PACKET_LEN (ETH_HLEN + VLAN_HLEN + ETH_DATA_LEN)
 #define GOOD_COPY_LEN	128
@@ -180,6 +188,39 @@
 	return (struct virtio_net_hdr_mrg_rxbuf *)skb->cb;
 }
 
+/* SAI: changes for ASF  */
+#ifdef CONFIG_AS_FASTPATH
+devfp_hook_t devfp_rx_hook_veth;
+devfp_hook_t devfp_tx_hook_veth;
+int devfp_register_rx_hook_veth(devfp_hook_t hook)
+{
+        devfp_rx_hook_veth = hook;
+        printk(KERN_INFO "hook =0x%p, devfp_rx_hook_veth=0x%p\n", hook, devfp_rx_hook_veth);
+        return 0;
+}
+EXPORT_SYMBOL(devfp_register_rx_hook_veth);
+int devfp_deregister_rx_hook_veth(void)
+{
+        devfp_rx_hook_veth = NULL;
+        return 0;
+}
+EXPORT_SYMBOL(devfp_deregister_rx_hook_veth);
+int devfp_register_tx_hook_veth(devfp_hook_t hook)
+{
+        devfp_tx_hook_veth = hook;
+        printk(KERN_INFO "hook =0x%p, devfp_tx_hook_veth=0x%p\n", hook, devfp_tx_hook_veth);
+        return 0;
+}
+EXPORT_SYMBOL(devfp_register_tx_hook_veth);
+
+int devfp_deregister_tx_hook_veth(void)
+{
+        devfp_tx_hook_veth = NULL;
+        return 0;
+}
+EXPORT_SYMBOL(devfp_deregister_tx_hook_veth);
+#endif
+
 /*
  * private is used to chain pages for big packets, put the whole
  * most recent used list in the beginning for reuse
@@ -517,7 +558,17 @@
 	}
 
 	skb_mark_napi_id(skb, &rq->napi);
+#ifdef CONFIG_AS_FASTPATH
+	skb->pkt_type = PACKET_HOST;
 
+        printk("skb->pkt_type = %d\n", skb->pkt_type);
+        if (devfp_rx_hook_veth) {
+                printk("Calling devfp_rx_hook %p\n", devfp_rx_hook_veth);
+
+                if (devfp_rx_hook_veth(skb, dev) == AS_FP_STOLEN)
+                        return;
+        }
+#endif
 	netif_receive_skb(skb);
 	return;
 
@@ -849,6 +900,11 @@
 	bool can_push;
 
 	pr_debug("%s: xmit %p %pM\n", vi->dev->name, skb, dest);
+#ifdef CONFIG_AS_FASTPATH
+        if (devfp_tx_hook_veth && (skb->pkt_type != PACKET_FASTROUTE))
+                if (devfp_tx_hook_veth(skb, vi->dev) == AS_FP_STOLEN)
+                        return 0;
+#endif
 
 	can_push = vi->any_header_sg &&
 		!((unsigned long)skb->data & (__alignof__(*hdr) - 1)) &&
@@ -906,6 +962,75 @@
 	return virtqueue_add_outbuf(sq->vq, sq->sg, num_sg, skb, GFP_ATOMIC);
 }
 
+#ifdef CONFIG_AS_FASTPATH
+static int asf_xmit_skb(struct send_queue *sq, struct sk_buff *skb)
+{
+	struct virtio_net_hdr_mrg_rxbuf *hdr;
+	const unsigned char *dest = ((struct ethhdr *)skb->data)->h_dest;
+	struct virtnet_info *vi = sq->vq->vdev->priv;
+	unsigned num_sg;
+	unsigned hdr_len = vi->hdr_len;
+	bool can_push;
+
+	pr_debug("%s: xmit %p %pM\n", vi->dev->name, skb, dest);
+
+	can_push = vi->any_header_sg &&
+		!((unsigned long)skb->data & (__alignof__(*hdr) - 1)) &&
+		!skb_header_cloned(skb) && skb_headroom(skb) >= hdr_len;
+	/* Even if we can, don't push here yet as this would skew
+	 * csum_start offset below. */
+	if (can_push)
+		hdr = (struct virtio_net_hdr_mrg_rxbuf *)(skb->data - hdr_len);
+	else
+		hdr = skb_vnet_hdr(skb);
+
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		hdr->hdr.flags = VIRTIO_NET_HDR_F_NEEDS_CSUM;
+		hdr->hdr.csum_start = cpu_to_virtio16(vi->vdev,
+						skb_checksum_start_offset(skb));
+		hdr->hdr.csum_offset = cpu_to_virtio16(vi->vdev,
+							 skb->csum_offset);
+	} else {
+		hdr->hdr.flags = 0;
+		hdr->hdr.csum_offset = hdr->hdr.csum_start = 0;
+	}
+
+	if (skb_is_gso(skb)) {
+		hdr->hdr.hdr_len = cpu_to_virtio16(vi->vdev, skb_headlen(skb));
+		hdr->hdr.gso_size = cpu_to_virtio16(vi->vdev,
+						    skb_shinfo(skb)->gso_size);
+		if (skb_shinfo(skb)->gso_type & SKB_GSO_TCPV4)
+			hdr->hdr.gso_type = VIRTIO_NET_HDR_GSO_TCPV4;
+		else if (skb_shinfo(skb)->gso_type & SKB_GSO_TCPV6)
+			hdr->hdr.gso_type = VIRTIO_NET_HDR_GSO_TCPV6;
+		else if (skb_shinfo(skb)->gso_type & SKB_GSO_UDP)
+			hdr->hdr.gso_type = VIRTIO_NET_HDR_GSO_UDP;
+		else
+			BUG();
+		if (skb_shinfo(skb)->gso_type & SKB_GSO_TCP_ECN)
+			hdr->hdr.gso_type |= VIRTIO_NET_HDR_GSO_ECN;
+	} else {
+		hdr->hdr.gso_type = VIRTIO_NET_HDR_GSO_NONE;
+		hdr->hdr.gso_size = hdr->hdr.hdr_len = 0;
+	}
+
+	if (vi->mergeable_rx_bufs)
+		hdr->num_buffers = 0;
+
+	sg_init_table(sq->sg, MAX_SKB_FRAGS + 2);
+	if (can_push) {
+		__skb_push(skb, hdr_len);
+		num_sg = skb_to_sgvec(skb, sq->sg, 0, skb->len);
+		/* Pull header back to avoid skew in tx bytes calculations. */
+		__skb_pull(skb, hdr_len);
+	} else {
+		sg_set_buf(sq->sg, hdr, hdr_len);
+		num_sg = skb_to_sgvec(skb, sq->sg + 1, 0, skb->len) + 1;
+	}
+	return virtqueue_add_outbuf(sq->vq, sq->sg, num_sg, skb, GFP_ATOMIC);
+}
+EXPORT_SYMBOL(asf_xmit_skb);
+#endif
 static netdev_tx_t start_xmit(struct sk_buff *skb, struct net_device *dev)
 {
 	struct virtnet_info *vi = netdev_priv(dev);
diff -Naur wo_vivid/include/linux/netfilter/nf_conntrack_tcp.h c_vivid/include/linux/netfilter/nf_conntrack_tcp.h
--- wo_vivid/include/linux/netfilter/nf_conntrack_tcp.h	2016-02-10 11:54:49.592000000 +0530
+++ c_vivid/include/linux/netfilter/nf_conntrack_tcp.h	2016-02-10 11:14:57.124000000 +0530
@@ -11,6 +11,12 @@
 	u_int32_t	td_maxack;	/* max of ack */
 	u_int8_t	td_scale;	/* window scale factor */
 	u_int8_t	flags;		/* per direction options */
+#ifdef CONFIG_AS_FASTPATH
+	u_int32_t	td_tcptimestamp;/* Time Stamp */
+	int32_t		td_delta;	/* for Packet mangling */
+	/* Last window advertisement seen in dir */
+	u_int32_t	td_rcvwin;
+#endif
 };
 
 struct ip_ct_tcp {
diff -Naur wo_vivid/include/linux/netfilter_ipv4/ip_tables.h c_vivid/include/linux/netfilter_ipv4/ip_tables.h
--- wo_vivid/include/linux/netfilter_ipv4/ip_tables.h	2016-02-10 11:56:49.440000000 +0530
+++ c_vivid/include/linux/netfilter_ipv4/ip_tables.h	2016-02-10 11:18:24.212000000 +0530
@@ -68,6 +68,13 @@
 				 const struct net_device *in,
 				 const struct net_device *out,
 				 struct xt_table *table);
+#ifdef CONFIG_AS_FASTPATH
+struct firewall_asfctrl {
+	void (*firewall_asfctrl_cb)(void);
+};
+
+extern void hook_firewall_asfctrl_cb(const struct firewall_asfctrl *);
+#endif
 
 #ifdef CONFIG_COMPAT
 #include <net/compat.h>
diff -Naur wo_vivid/include/linux/skbuff.h c_vivid/include/linux/skbuff.h
--- wo_vivid/include/linux/skbuff.h	2016-02-10 11:57:26.136000000 +0530
+++ c_vivid/include/linux/skbuff.h	2016-02-10 11:19:03.608000000 +0530
@@ -529,8 +529,11 @@
 	 * want to keep them across layers you have to do a skb_clone()
 	 * first. This is owned by whoever has the skb queued ATM.
 	 */
+#ifdef CONFIG_AS_FASTPATH
+	char			cb[96] __aligned(8);
+#else
 	char			cb[48] __aligned(8);
-
+#endif
 	unsigned long		_skb_refdst;
 	void			(*destructor)(struct sk_buff *skb);
 #ifdef CONFIG_XFRM
diff -Naur wo_vivid/include/net/ip6_route.h c_vivid/include/net/ip6_route.h
--- wo_vivid/include/net/ip6_route.h	2016-02-10 11:58:36.820000000 +0530
+++ c_vivid/include/net/ip6_route.h	2016-02-10 11:20:11.784000000 +0530
@@ -197,5 +197,8 @@
 {
 	return &rt->rt6i_gateway;
 }
-
+#ifdef CONFIG_AS_FASTPATH
+typedef void ipv6_route_flush_hook(void);
+void ipv6_route_hook_fn_register(ipv6_route_flush_hook *flush);
+#endif
 #endif
diff -Naur wo_vivid/include/net/route.h c_vivid/include/net/route.h
--- wo_vivid/include/net/route.h	2016-02-10 11:59:04.400000000 +0530
+++ c_vivid/include/net/route.h	2016-02-10 11:20:47.500000000 +0530
@@ -301,6 +301,10 @@
 		return iif;
 	return skb->skb_iif;
 }
+#ifdef CONFIG_AS_FASTPATH
+typedef void route_flush_hook(void);
+void route_hook_fn_register(route_flush_hook *flush);
+#endif
 
 extern int sysctl_ip_default_ttl;
 
diff -Naur wo_vivid/include/net/xfrm.h c_vivid/include/net/xfrm.h
--- wo_vivid/include/net/xfrm.h	2016-02-10 11:59:52.808000000 +0530
+++ c_vivid/include/net/xfrm.h	2016-02-10 11:21:11.876000000 +0530
@@ -227,7 +227,10 @@
 
 	/* Security context */
 	struct xfrm_sec_ctx	*security;
-
+#ifdef CONFIG_AS_FASTPATH
+	uintptr_t	asf_sa_cookie;
+	u32		asf_sa_direction;
+#endif
 	/* Private data of this transformer, format is opaque,
 	 * interpreted by xfrm_type methods. */
 	void			*data;
@@ -542,6 +545,9 @@
 	struct xfrm_lifetime_cfg lft;
 	struct xfrm_lifetime_cur curlft;
 	struct xfrm_policy_walk_entry walk;
+#ifdef CONFIG_AS_FASTPATH
+	u32			asf_cookie;
+#endif
 	struct xfrm_policy_queue polq;
 	u8			type;
 	u8			action;
@@ -1810,4 +1816,29 @@
 
 	return 0;
 }
+#ifdef CONFIG_AS_FASTPATH
+struct asf_ipsec_callbackfn_s {
+	/* Callback to offload the encryption Info*/
+	int	(*ipsec_enc_hook)(struct xfrm_policy *xp,
+			struct xfrm_state *xfrm, struct flowi *fl, int ifindex);
+
+	/* Callback to offload the decryption Info*/
+	int	(*ipsec_dec_hook)(struct xfrm_policy *xp,
+			struct xfrm_state *xfrm, struct flowi *fl, int ifindex);
+
+	/* Callback to receive the live SA Sync Info*/
+	int	(*ipsec_sync_sa)(struct xfrm_state *xfrm, int dir,
+			int seq_no, int bytes);
+
+	/* Callback to send the packet to ASF for further IPSEC processing */
+	int	(*ipsec_encrypt_n_send)(struct sk_buff *skb,
+			struct xfrm_state *xfrm);
+
+	/* Callback to send the packet to ASF for further IPSEC processing */
+	int	(*ipsec_decrypt_n_send)(struct sk_buff *skb,
+			struct xfrm_state *xfrm);
+};
+extern struct asf_ipsec_callbackfn_s	asf_cb_fns;
+#endif
+
 #endif	/* _NET_XFRM_H */
diff -Naur wo_vivid/net/ipv4/fib_semantics.c c_vivid/net/ipv4/fib_semantics.c
--- wo_vivid/net/ipv4/fib_semantics.c	2016-02-10 12:09:28.404000000 +0530
+++ c_vivid/net/ipv4/fib_semantics.c	2016-02-10 11:33:08.712000000 +0530
@@ -218,6 +218,7 @@
 		kfree(fi->fib_metrics);
 	kfree(fi);
 }
+//EXPORT_SYMBOL_GPL(free_fib_info_rcu);
 
 void free_fib_info(struct fib_info *fi)
 {
@@ -234,6 +235,7 @@
 #endif
 	call_rcu(&fi->rcu, free_fib_info_rcu);
 }
+EXPORT_SYMBOL_GPL(free_fib_info);
 
 void fib_release_info(struct fib_info *fi)
 {
diff -Naur wo_vivid/net/ipv4/ip_forward.c c_vivid/net/ipv4/ip_forward.c
--- wo_vivid/net/ipv4/ip_forward.c	2016-02-10 12:01:56.864000000 +0530
+++ c_vivid/net/ipv4/ip_forward.c	2016-02-10 11:24:44.208000000 +0530
@@ -156,3 +156,6 @@
 	kfree_skb(skb);
 	return NET_RX_DROP;
 }
+#ifdef CONFIG_AS_FASTPATH
+EXPORT_SYMBOL(ip_forward);
+#endif
diff -Naur wo_vivid/net/ipv4/netfilter/ip_tables.c c_vivid/net/ipv4/netfilter/ip_tables.c
--- wo_vivid/net/ipv4/netfilter/ip_tables.c	2016-02-10 12:02:54.356000000 +0530
+++ c_vivid/net/ipv4/netfilter/ip_tables.c	2016-02-10 11:26:03.144000000 +0530
@@ -62,6 +62,18 @@
 #define static
 #define inline
 #endif
+#ifdef CONFIG_ASF_INGRESS_MARKER
+marker_add_hook *marker_add_fn;
+marker_flush_hook *marker_flush_fn;
+
+void marker_v4_hook_fn_register(marker_add_hook *add,
+			    marker_flush_hook *flush)
+{
+	marker_add_fn = add;
+	marker_flush_fn = flush;
+}
+EXPORT_SYMBOL(marker_v4_hook_fn_register);
+#endif
 
 void *ipt_alloc_initial_table(const struct xt_table *info)
 {
@@ -872,7 +884,65 @@
 		if (newinfo->entries[i] && newinfo->entries[i] != entry0)
 			memcpy(newinfo->entries[i], entry0, newinfo->size);
 	}
+#ifdef CONFIG_ASF_INGRESS_MARKER
+	/* Rules has been verified now safe to offload to ASF */
+	if (marker_add_fn && (0 == strcmp(repl->name, "mangle"))) {
+		struct xt_entry_match *m;
+		struct xt_entry_target *t;
+		markerRule_t rules[MAX_MARKER_RULES] = {};
+		uint16_t *sport, *dport;
+		uint32_t  num = 0;
+
+		/* Whether It is FLUSH request ? */
+		/* Note: num_entries are always equals to num_counters +1, when adding Rules
+		   while num_entries comes as '6' as default value when FLUSH is required */
+		if ((repl->num_entries == 6) && (repl->num_entries < repl->num_counters)) {
+			if (marker_flush_fn)
+				marker_flush_fn();
+			return ret;
+		}
+		xt_entry_foreach(iter, entry0, newinfo->size)
+		{
+			/* Only POSTROUTING CHAINS */
+			if (iter->comefrom != (0x1 << NF_INET_POST_ROUTING))
+				continue;
+			if ((iter->ip.proto != 17/*UDP */) &&
+					(iter->ip.proto != 6/*TCP */))
+				continue;
+
+			if (num == MAX_MARKER_RULES) {
+				printk(KERN_INFO "Maximum %d Rule permitted\n",
+								MAX_MARKER_RULES);
+				break;
+			}
+			m = (void *)iter + sizeof(struct ipt_entry);
+			t = (void *)iter + iter->target_offset;
+			if (0 != strcmp(t->u.kernel.target->name, "DSCP"))
+				continue;
+
+			rules[num].src_ip[0] = iter->ip.src.s_addr;
+			rules[num].dst_ip[0] = iter->ip.dst.s_addr;
+			rules[num].proto = iter->ip.proto;
+			/* We are passing Port Mask instead of Value , since mask = value.
+			   But when Port are not configured, we get 0xFFFF to indicate that
+			   ANY port value is accepted. */
+			sport = (uint16_t *)&m->data[2];
+			dport = (uint16_t *)&m->data[6];
+			rules[num].src_port = *sport;
+			rules[num].dst_port = *dport;
+			rules[num].uciDscp = (t->data[0] << 2);
 
+			num++;
+		}
+		if (num > 0) {
+			marker_db_t arg;
+
+			arg.rule = &rules[0];
+			arg.num_rules = num;
+			marker_add_fn(&arg);
+		}
+	}
+#endif
 	return ret;
 }
 
@@ -1172,6 +1242,16 @@
 
 	return ret;
 }
+#ifdef CONFIG_AS_FASTPATH
+void (*pfnfirewall_asfctrl)(void);
+
+void hook_firewall_asfctrl_cb(const struct firewall_asfctrl *fwasfctrl)
+{
+	pfnfirewall_asfctrl = fwasfctrl->firewall_asfctrl_cb;
+}
+EXPORT_SYMBOL(hook_firewall_asfctrl_cb);
+EXPORT_SYMBOL(pfnfirewall_asfctrl);
+#endif
 
 static int
 __do_replace(struct net *net, const char *name, unsigned int valid_hooks,
@@ -1237,6 +1317,13 @@
 	}
 	vfree(counters);
 	xt_table_unlock(t);
+
+#ifdef CONFIG_AS_FASTPATH
+	/* Call the  ASF CTRL CB */
+	if (!ret && pfnfirewall_asfctrl)
+		pfnfirewall_asfctrl();
+#endif
+
 	return ret;
 
  put_module:
diff -Naur wo_vivid/net/ipv4/route.c c_vivid/net/ipv4/route.c
--- wo_vivid/net/ipv4/route.c	2016-02-10 12:03:26.304000000 +0530
+++ c_vivid/net/ipv4/route.c	2016-02-10 11:26:37.344000000 +0530
@@ -187,6 +187,9 @@
 	ECN_OR_COST(INTERACTIVE_BULK)
 };
 EXPORT_SYMBOL(ip_tos2prio);
+#ifdef CONFIG_AS_FASTPATH
+static route_flush_hook *route_flush_fn;
+#endif
 
 static DEFINE_PER_CPU(struct rt_cache_stat, rt_cache_stat);
 #define RT_CACHE_STAT_INC(field) raw_cpu_inc(rt_cache_stat.field)
@@ -434,6 +437,10 @@
 void rt_cache_flush(struct net *net)
 {
 	rt_genid_bump_ipv4(net);
+#ifdef CONFIG_AS_FASTPATH
+	if (route_flush_fn)
+		route_flush_fn();
+#endif
 }
 
 static struct neighbour *ipv4_neigh_lookup(const struct dst_entry *dst,
@@ -2182,6 +2189,13 @@
 	return rth;
 }
 EXPORT_SYMBOL_GPL(__ip_route_output_key);
+#ifdef CONFIG_AS_FASTPATH
+void route_hook_fn_register(route_flush_hook *flush)
+{
+	route_flush_fn = flush;
+}
+EXPORT_SYMBOL(route_hook_fn_register);
+#endif
 
 static struct dst_entry *ipv4_blackhole_dst_check(struct dst_entry *dst, u32 cookie)
 {
diff -Naur wo_vivid/net/ipv6/netfilter/ip6_tables.c c_vivid/net/ipv6/netfilter/ip6_tables.c
--- wo_vivid/net/ipv6/netfilter/ip6_tables.c	2016-02-10 12:04:50.412000000 +0530
+++ c_vivid/net/ipv6/netfilter/ip6_tables.c	2016-02-10 11:28:20.492000000 +0530
@@ -882,7 +882,70 @@
 		if (newinfo->entries[i] && newinfo->entries[i] != entry0)
 			memcpy(newinfo->entries[i], entry0, newinfo->size);
 	}
+#ifdef CONFIG_ASF_INGRESS_MARKER
+	/* Rules has been verified now safe to offload to ASF */
+	if (marker_v6_add_fn && (0 == strcmp(repl->name, "mangle"))) {
+		struct xt_entry_match *m;
+		struct xt_entry_target *t;
+		markerRule_t rules[MAX_MARKER_RULES] = {};
+		uint16_t *sport, *dport;
+		uint32_t  num = 0;
+
+		/* Whether It is FLUSH request ? */
+		/* Note: num_entries are always equals to num_counters +1, when adding Rules
+		   while num_entries comes as '6' as default value when FLUSH is required */
+		if ((repl->num_entries == 6) && (repl->num_entries < repl->num_counters)) {
+			if (marker_v6_flush_fn)
+				marker_v6_flush_fn();
+			return ret;
+		}
+		xt_entry_foreach(iter, entry0, newinfo->size)
+		{
+			/* Only POSTROUTING CHAINS */
+			if (iter->comefrom != (0x1 << NF_INET_POST_ROUTING))
+				continue;
+			if ((iter->ipv6.proto != 17/*UDP */) && (iter->ipv6.proto != 6/*TCP */))
+				continue;
+
+			if (num == MAX_MARKER_RULES) {
+				printk(KERN_INFO "Maximum %d Rule permitted\n",
+								MAX_MARKER_RULES);
+				break;
+			}
+			m = (void *)iter + sizeof(struct ip6t_entry);
+			t = (void *)iter + iter->target_offset;
+			if (0 != strcmp(t->u.kernel.target->name, "DSCP"))
+				continue;
+
+			rules[num].src_ip[0] = iter->ipv6.src.in6_u.u6_addr32[0];
+			rules[num].src_ip[1] = iter->ipv6.src.in6_u.u6_addr32[1];
+			rules[num].src_ip[2] = iter->ipv6.src.in6_u.u6_addr32[2];
+			rules[num].src_ip[3] = iter->ipv6.src.in6_u.u6_addr32[3];
+			rules[num].dst_ip[0] = iter->ipv6.dst.in6_u.u6_addr32[0];
+			rules[num].dst_ip[1] = iter->ipv6.dst.in6_u.u6_addr32[1];
+			rules[num].dst_ip[2] = iter->ipv6.dst.in6_u.u6_addr32[2];
+			rules[num].dst_ip[3] = iter->ipv6.dst.in6_u.u6_addr32[3];
+			rules[num].proto = iter->ipv6.proto;
+			/* We are passing Port Mask instead of Value , since mask = value.
+			   But when Port are not configured, we get 0xFFFF to indicate that
+			   ANY port value is accepted. */
+			sport = (uint16_t *)&m->data[2];
+			dport = (uint16_t *)&m->data[6];
+			rules[num].src_port = *sport;
+			rules[num].dst_port = *dport;
+			rules[num].uciDscp = (t->data[0] << 2);
 
+			num++;
+		}
+		if (num > 0) {
+			marker_db_t arg;
+
+			arg.rule = &rules[0];
+			arg.num_rules = num;
+			marker_v6_add_fn(&arg);
+		}
+	}
+#endif
 	return ret;
 }
 
@@ -1182,6 +1245,9 @@
 
 	return ret;
 }
+#ifdef CONFIG_AS_FASTPATH
+extern void (*pfnfirewall_asfctrl)(void);
+#endif
 
 static int
 __do_replace(struct net *net, const char *name, unsigned int valid_hooks,
@@ -1247,6 +1313,13 @@
 	}
 	vfree(counters);
 	xt_table_unlock(t);
+
+#ifdef CONFIG_AS_FASTPATH
+	/* Call the  ASF CTRL CB */
+	if (!ret && pfnfirewall_asfctrl)
+		pfnfirewall_asfctrl();
+#endif
+
 	return ret;
 
  put_module:
diff -Naur wo_vivid/net/ipv6/route.c c_vivid/net/ipv6/route.c
--- wo_vivid/net/ipv6/route.c	2016-02-10 12:05:22.576000000 +0530
+++ c_vivid/net/ipv6/route.c	2016-02-10 11:29:02.936000000 +0530
@@ -64,6 +64,9 @@
 #ifdef CONFIG_SYSCTL
 #include <linux/sysctl.h>
 #endif
+#ifdef CONFIG_AS_FASTPATH
+static ipv6_route_flush_hook *ipv6_route_flush_fn;
+#endif
 
 enum rt6_nud_state {
 	RT6_NUD_FAIL_HARD = -3,
@@ -862,6 +865,10 @@
 	write_lock_bh(&table->tb6_lock);
 	err = fib6_add(&table->tb6_root, rt, info, mx, mx_len);
 	write_unlock_bh(&table->tb6_lock);
+#ifdef CONFIG_AS_FASTPATH
+	if ((!err) && ipv6_route_flush_fn)
+		ipv6_route_flush_fn();
+#endif
 
 	return err;
 }
@@ -1025,6 +1032,9 @@
 
 	skb_dst_set(skb, ip6_route_input_lookup(net, skb->dev, &fl6, flags));
 }
+EXPORT_SYMBOL_GPL(ip6_route_input);
+
+
 
 static struct rt6_info *ip6_pol_route_output(struct net *net, struct fib6_table *table,
 					     struct flowi6 *fl6, int flags)
@@ -1708,6 +1718,12 @@
 
 out:
 	ip6_rt_put(rt);
+
+#ifdef CONFIG_AS_FASTPATH
+	if ((!err) && ipv6_route_flush_fn)
+		ipv6_route_flush_fn();
+#endif
+
 	return err;
 }
 
@@ -3233,6 +3249,13 @@
 	goto out;
 }
 
+#ifdef CONFIG_AS_FASTPATH
+void ipv6_route_hook_fn_register(ipv6_route_flush_hook *flush)
+{
+	ipv6_route_flush_fn = flush;
+}
+EXPORT_SYMBOL(ipv6_route_hook_fn_register);
+#endif
 void ip6_route_cleanup(void)
 {
 	unregister_netdevice_notifier(&ip6_route_dev_notifier);
diff -Naur wo_vivid/net/netfilter/nf_conntrack_proto_tcp.c c_vivid/net/netfilter/nf_conntrack_proto_tcp.c
--- wo_vivid/net/netfilter/nf_conntrack_proto_tcp.c	2016-02-10 12:06:36.140000000 +0530
+++ c_vivid/net/netfilter/nf_conntrack_proto_tcp.c	2016-02-10 11:30:26.796000000 +0530
@@ -706,6 +706,48 @@
 				state->retrans = 0;
 			}
 		}
+
+#ifdef CONFIG_AS_FASTPATH
+	state->seen[dir].td_delta = receiver_offset;
+	state->seen[dir].td_rcvwin = win;
+	/* Setting Time stamp */
+	{
+		unsigned char *tcpopt;
+		unsigned char *endptr;
+		int     optlen;
+		tcpopt = (unsigned char *)(tcph) + 20;
+		optlen = tcph->doff * 4 - 20;
+		if (optlen > 0) {
+			endptr = tcpopt + optlen;
+			while (tcpopt < endptr) {
+				if (tcpopt[1] <= 0)
+					break;
+
+				switch (*tcpopt) {
+				case TCPOPT_EOL:
+				case TCPOPT_NOP:
+					tcpopt++;
+					break;
+				case TCPOPT_MSS:
+					tcpopt += 4; /* 4 byte option length */
+					break;
+				case TCPOPT_WINDOW:
+					tcpopt += 3; /* 3 byte option length */
+					break;
+				case TCPOPT_TIMESTAMP:
+					state->seen[dir].td_tcptimestamp =
+						ntohl(*((unsigned long *)
+							(tcpopt + 2)));
+					goto DONE;
+				default:
+					tcpopt += tcpopt[1];
+					break;
+				}
+			}
+		}
+	}
+DONE:
+#endif
 		res = true;
 	} else {
 		res = false;
diff -Naur wo_vivid/net/xfrm/xfrm_input.c c_vivid/net/xfrm/xfrm_input.c
--- wo_vivid/net/xfrm/xfrm_input.c	2016-02-10 12:08:17.312000000 +0530
+++ c_vivid/net/xfrm/xfrm_input.c	2016-02-10 11:31:29.368000000 +0530
@@ -258,6 +258,17 @@
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMISMATCH);
 			goto drop_unlock;
 		}
+#ifdef CONFIG_AS_FASTPATH
+		if (!x->asf_sa_cookie && asf_cb_fns.ipsec_dec_hook)
+			asf_cb_fns.ipsec_dec_hook(NULL, x, NULL, skb->skb_iif);
+
+		spin_unlock(&x->lock);
+		if (x->asf_sa_cookie && asf_cb_fns.ipsec_decrypt_n_send) {
+			if (!asf_cb_fns.ipsec_decrypt_n_send(skb, x))
+				return 0;
+		}
+		spin_lock(&x->lock);
+#endif
 
 		if (x->repl->check(x, skb, seq)) {
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATESEQERROR);
diff -Naur wo_vivid/net/xfrm/xfrm_output.c c_vivid/net/xfrm/xfrm_output.c
--- wo_vivid/net/xfrm/xfrm_output.c	2016-02-10 12:08:23.808000000 +0530
+++ c_vivid/net/xfrm/xfrm_output.c	2016-02-10 11:31:42.184000000 +0530
@@ -53,6 +53,16 @@
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
 			goto error_nolock;
 		}
+#ifdef CONFIG_AS_FASTPATH
+		if (!x->asf_sa_cookie && asf_cb_fns.ipsec_enc_hook)
+			asf_cb_fns.ipsec_enc_hook(NULL, x, NULL, skb->skb_iif);
+
+		if (x->asf_sa_cookie && asf_cb_fns.ipsec_encrypt_n_send) {
+			err = -EINPROGRESS;
+			if (!asf_cb_fns.ipsec_encrypt_n_send(skb, x))
+				goto out;
+		}
+#endif
 
 		err = x->outer_mode->output(x, skb);
 		if (err) {
diff -Naur wo_vivid/net/xfrm/xfrm_policy.c c_vivid/net/xfrm/xfrm_policy.c
--- wo_vivid/net/xfrm/xfrm_policy.c	2016-02-10 12:08:30.100000000 +0530
+++ c_vivid/net/xfrm/xfrm_policy.c	2016-02-10 11:31:57.488000000 +0530
@@ -58,6 +58,32 @@
 static void __xfrm_policy_link(struct xfrm_policy *pol, int dir);
 static struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,
 						int dir);
+#ifdef CONFIG_AS_FASTPATH
+struct asf_ipsec_callbackfn_s	asf_cb_fns = {0};
+
+void  register_ipsec_offload_hook(struct asf_ipsec_callbackfn_s *p_fn_list)
+{
+	asf_cb_fns.ipsec_enc_hook = p_fn_list->ipsec_enc_hook;
+	asf_cb_fns.ipsec_dec_hook = p_fn_list->ipsec_dec_hook;
+	asf_cb_fns.ipsec_sync_sa = p_fn_list->ipsec_sync_sa;
+	asf_cb_fns.ipsec_encrypt_n_send
+			= p_fn_list->ipsec_encrypt_n_send;
+	asf_cb_fns.ipsec_decrypt_n_send
+			= p_fn_list->ipsec_decrypt_n_send;
+
+}
+EXPORT_SYMBOL(register_ipsec_offload_hook);
+
+void unregister_ipsec_offload_hook(void)
+{
+	asf_cb_fns.ipsec_enc_hook = NULL;
+	asf_cb_fns.ipsec_dec_hook = NULL;
+	asf_cb_fns.ipsec_sync_sa = NULL;
+	asf_cb_fns.ipsec_encrypt_n_send = NULL;
+	asf_cb_fns.ipsec_decrypt_n_send = NULL;
+}
+EXPORT_SYMBOL(unregister_ipsec_offload_hook);
+#endif	/* CONFIG_AS_FASTPATH */
 
 static inline bool
 __xfrm4_selector_match(const struct xfrm_selector *sel, const struct flowi *fl)
@@ -794,6 +820,9 @@
 		__xfrm_policy_unlink(delpol, dir);
 	}
 	policy->index = delpol ? delpol->index : xfrm_gen_index(net, dir, policy->index);
+#ifdef CONFIG_AS_FASTPATH
+	policy->asf_cookie = delpol ? delpol->asf_cookie : 0;
+#endif	
 	hlist_add_head(&policy->byidx, net->xfrm.policy_byidx+idx_hash(net, policy->index));
 	policy->curlft.add_time = get_seconds();
 	policy->curlft.use_time = 0;
@@ -1153,6 +1182,8 @@
 #endif
 	return xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN, fl, family, dir);
 }
+EXPORT_SYMBOL(__xfrm_policy_lookup);
+
 
 static int flow_to_policy_dir(int dir)
 {
@@ -1352,6 +1383,11 @@
 		newp->xfrm_nr = old->xfrm_nr;
 		newp->index = old->index;
 		newp->type = old->type;
+
+#ifdef CONFIG_AS_FASTPATH
+		newp->asf_cookie = old->asf_cookie;
+#endif
+
 		memcpy(newp->xfrm_vec, old->xfrm_vec,
 		       newp->xfrm_nr*sizeof(struct xfrm_tmpl));
 		write_lock_bh(&net->xfrm.xfrm_policy_lock);
diff -Naur wo_vivid/net/xfrm/xfrm_state.c c_vivid/net/xfrm/xfrm_state.c
--- wo_vivid/net/xfrm/xfrm_state.c	2016-02-10 12:08:41.308000000 +0530
+++ c_vivid/net/xfrm/xfrm_state.c	2016-02-10 12:16:11.824000000 +0530
@@ -1692,7 +1692,75 @@
 
 	spin_unlock(&x->lock);
 }
+#ifdef CONFIG_AS_FASTPATH
+struct xfrm_policy *xfrm_state_policy_mapping(struct xfrm_state *xfrm)
+{
+	struct xfrm_policy *xp = 0, *matched_pol = 0;
+	struct net *xfrm_net = xs_net(xfrm);
+	struct list_head *list_policy_head = &xfrm_net->xfrm.policy_all;
+	struct xfrm_policy_walk_entry *x;
+	struct xfrm_tmpl *tmpl;
+	unsigned int dir;
+
+	if (!list_policy_head) {
+		return matched_pol;
+	}
+	
+	x = list_first_entry(list_policy_head,
+				struct xfrm_policy_walk_entry, all);
+	if (!x) {
+				return matched_pol;
+	}
+	if (xfrm->props.family == AF_INET) {
+			list_for_each_entry_from(x, list_policy_head, all) {
+			if (x->dead)
+			{
+				continue;
+			}
+			xp = container_of(x, struct xfrm_policy, walk);
+			tmpl = &xp->xfrm_vec[0];
+			dir = xfrm_policy_id2dir(xp->index);
+			if (dir <= XFRM_POLICY_OUT &&
+				tmpl->id.daddr.a4 == xfrm->id.daddr.a4 &&
+				tmpl->saddr.a4 == xfrm->props.saddr.a4 &&
+				xfrm->props.reqid == tmpl->reqid &&
+				xfrm->props.mode == tmpl->mode) {
+					matched_pol = xp;
+					xfrm->asf_sa_direction = dir;
+					break;
+			}
+		}
+	} else if (xfrm->props.family == AF_INET6) {
+		list_for_each_entry_from(x, list_policy_head, all) {
+			if (x->dead)
+			{
+				continue;
+			}
+			xp = container_of(x, struct xfrm_policy, walk);
+			tmpl = &xp->xfrm_vec[0];
+			dir = xfrm_policy_id2dir(xp->index);
+			if (dir <= XFRM_POLICY_OUT &&
+				!memcmp(tmpl->id.daddr.a6,
+						xfrm->id.daddr.a6, 16) &&
+				!memcmp(tmpl->saddr.a6,
+						xfrm->props.saddr.a6, 16) &&
+				xfrm->props.reqid == tmpl->reqid &&
+				xfrm->props.mode == tmpl->mode) {
+					matched_pol = xp;
+					xfrm->asf_sa_direction = dir;
+					break;
+			}
+		}
+	}
+	 else
+	{
+		return NULL;
+	}
 
+	return matched_pol;
+}
+EXPORT_SYMBOL(xfrm_state_policy_mapping);
+#endif
 static LIST_HEAD(xfrm_km_list);
 
 void km_policy_notify(struct xfrm_policy *xp, int dir, const struct km_event *c)
@@ -1700,9 +1768,12 @@
 	struct xfrm_mgr *km;
 
 	rcu_read_lock();
-	list_for_each_entry_rcu(km, &xfrm_km_list, list)
+	list_for_each_entry_rcu(km, &xfrm_km_list, list) {
 		if (km->notify_policy)
+		{
 			km->notify_policy(xp, dir, c);
+		}
+	}
 	rcu_read_unlock();
 }
 
@@ -1710,9 +1781,12 @@
 {
 	struct xfrm_mgr *km;
 	rcu_read_lock();
-	list_for_each_entry_rcu(km, &xfrm_km_list, list)
+	list_for_each_entry_rcu(km, &xfrm_km_list, list) {
 		if (km->notify)
+		{
 			km->notify(x, c);
+		}
+	}
 	rcu_read_unlock();
 }
 
